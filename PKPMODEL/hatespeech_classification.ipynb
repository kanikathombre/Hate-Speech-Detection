{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "0Ki7USG-qRLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Data1.csv')"
      ],
      "metadata": {
        "id": "2YMkZcynqO_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your pandas DataFrame containing the dataset\n",
        "# Assuming 'labels' is the column containing the labels\n",
        "\n",
        "# Count the occurrences of each label type\n",
        "label_counts = df['Label'].value_counts()\n",
        "\n",
        "# Display the counts\n",
        "print(\"Counts of each type of hate speech and normal comments:\")\n",
        "print(label_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRlJFTEMqh3_",
        "outputId": "e9a94e83-2cf2-476a-cec1-b8ceb93a7f84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counts of each type of hate speech and normal comments:\n",
            "Label\n",
            "hatespeech    640\n",
            "normal        572\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF"
      ],
      "metadata": {
        "id": "cXPt94mjzcO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('/content/Data1.csv')\n",
        "X = df['Comment']\n",
        "y = df['Label']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize a TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
        "\n",
        "# Fit and transform the training data, transform the testing data\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n"
      ],
      "metadata": {
        "id": "ie5PM-rBhW3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr28mg2qgh3M",
        "outputId": "3e3e9ee7-f1d8-4a5a-9434-bb69e178988f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.7736625514403292\n",
            "\n",
            "Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "  hatespeech       0.83      0.75      0.78       134\n",
            "      normal       0.72      0.81      0.76       109\n",
            "\n",
            "    accuracy                           0.77       243\n",
            "   macro avg       0.77      0.78      0.77       243\n",
            "weighted avg       0.78      0.77      0.77       243\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Initialize the Random Forest classifier\n",
        "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "random_forest.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "rf_pred = random_forest.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the classifier\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_pred))\n",
        "print(\"\\nRandom Forest Classification Report:\\n\", classification_report(y_test, rf_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the SVM classifier\n",
        "svm_model = SVC(kernel='linear', random_state=42)  # 'linear' kernel is generally good for text\n",
        "\n",
        "# Train the classifier\n",
        "svm_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "svm_pred = svm_model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the classifier\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_pred))\n",
        "print(\"\\nSVM Classification Report:\\n\", classification_report(y_test, svm_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E60-Ht_khV0b",
        "outputId": "2574b017-439e-4ae4-dd78-1f092e021aa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.8024691358024691\n",
            "\n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "  hatespeech       0.82      0.82      0.82       134\n",
            "      normal       0.78      0.78      0.78       109\n",
            "\n",
            "    accuracy                           0.80       243\n",
            "   macro avg       0.80      0.80      0.80       243\n",
            "weighted avg       0.80      0.80      0.80       243\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WORD2VEC"
      ],
      "metadata": {
        "id": "RMjW2SgdzhDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import pandas as pd\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "# Load data\n",
        "df = pd.read_csv('/content/Data1.csv')\n",
        "X = df['Comment'].apply(gensim.utils.simple_preprocess)  # Tokenize text\n",
        "y = df['Label']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "NRjVE1LXyQX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train a Word2Vec model\n",
        "model_w2v = Word2Vec(sentences=X_train, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Use the trained model to transform words to vectors and then average those vectors to create a document vector\n",
        "def document_vector(word2vec_model, doc):\n",
        "    # remove out-of-vocabulary words\n",
        "    doc = [word for word in doc if word in word2vec_model.wv.index_to_key]\n",
        "    if len(doc) == 0:\n",
        "        return np.zeros(word2vec_model.vector_size)\n",
        "    return np.mean(word2vec_model.wv[doc], axis=0)\n",
        "\n",
        "X_train_w2v = np.array([document_vector(model_w2v, words) for words in X_train])\n",
        "X_test_w2v = np.array([document_vector(model_w2v, words) for words in X_test])\n"
      ],
      "metadata": {
        "id": "PQcoPaHTyVEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Random Forest classifier\n",
        "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "random_forest.fit(X_train_w2v, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "rf_pred = random_forest.predict(X_test_w2v)\n",
        "\n",
        "# Evaluate the classifier\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_pred))\n",
        "print(\"\\nRandom Forest Classification Report:\\n\", classification_report(y_test, rf_pred))\n"
      ],
      "metadata": {
        "id": "-Vkczxr6yZTn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03833fda-7b06-4923-f8ae-7c2bd3aef971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.6378600823045267\n",
            "\n",
            "Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "  hatespeech       0.66      0.70      0.68       134\n",
            "      normal       0.60      0.56      0.58       109\n",
            "\n",
            "    accuracy                           0.64       243\n",
            "   macro avg       0.63      0.63      0.63       243\n",
            "weighted avg       0.64      0.64      0.64       243\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the SVM classifier\n",
        "svm_model = SVC(kernel='linear', random_state=42)  # 'linear' kernel is generally good for text\n",
        "\n",
        "# Train the classifier\n",
        "svm_model.fit(X_train_w2v, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "svm_pred = svm_model.predict(X_test_w2v)\n",
        "\n",
        "# Evaluate the classifier\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_pred))\n",
        "print(\"\\nSVM Classification Report:\\n\", classification_report(y_test, svm_pred))\n"
      ],
      "metadata": {
        "id": "KI2yGRiWyrnH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "237cacd9-b0b8-4bac-be85-4825e3666e24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.551440329218107\n",
            "\n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "  hatespeech       0.55      1.00      0.71       134\n",
            "      normal       0.00      0.00      0.00       109\n",
            "\n",
            "    accuracy                           0.55       243\n",
            "   macro avg       0.28      0.50      0.36       243\n",
            "weighted avg       0.30      0.55      0.39       243\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}